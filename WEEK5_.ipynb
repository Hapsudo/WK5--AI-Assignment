{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# C. Preprocessing Pipeline and Feature Engineering"
      ],
      "metadata": {
        "id": "fEC0XEfmgO0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtfbNaS6gLMY",
        "outputId": "784e7738-9cf0-410a-89d8-697a57fb33ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[130  10]\n",
            " [ 54   6]]\n",
            "Precision: 0.38\n",
            "Recall: 0.10\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "\n",
        "# Step 1: Simulate Data\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'age': np.random.randint(20, 90, size=n_samples),\n",
        "    'gender': np.random.choice(['Male', 'Female'], size=n_samples),\n",
        "    'ethnicity': np.random.choice(['White', 'Black', 'Hispanic', 'Asian', 'Other'], size=n_samples),\n",
        "    'diagnosis_code': np.random.choice(['D1', 'D2', 'D3', 'D4'], size=n_samples),\n",
        "    'length_of_stay': np.random.randint(1, 15, size=n_samples),\n",
        "    'lab_result1': np.random.normal(100, 15, size=n_samples),\n",
        "    'lab_result2': np.random.normal(5, 1.5, size=n_samples),\n",
        "    'readmitted': np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3])  # 30% readmitted\n",
        "})\n",
        "\n",
        "# Step 2: Define features and target\n",
        "X = df.drop(\"readmitted\", axis=1)\n",
        "y = df[\"readmitted\"]\n",
        "\n",
        "# Step 3: Preprocessing\n",
        "numeric_features = ['age', 'length_of_stay', 'lab_result1', 'lab_result2']\n",
        "categorical_features = ['gender', 'ethnicity', 'diagnosis_code']\n",
        "\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_pipeline, numeric_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "# Step 4: Model pipeline\n",
        "model = make_pipeline(preprocessor, RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "\n",
        "# Step 5: Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Step 6: Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Predictions and evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 8: Metrics\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization (5 points)"
      ],
      "metadata": {
        "id": "osXEQjYggpxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'randomforestclassifier__n_estimators': [100, 200],\n",
        "    'randomforestclassifier__max_depth': [5, 10, None]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='recall')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbf61BkOgrrf",
        "outputId": "fbaee0e4-f452-4ae4-a9e3-05b3ab9e2cf4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'randomforestclassifier__max_depth': None, 'randomforestclassifier__n_estimators': 100}\n"
          ]
        }
      ]
    }
  ]
}